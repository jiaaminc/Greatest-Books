#Webscraping Tool 
base_url = "https://thegreatestbooks.org"

def get_book_links(page=1):
    """Fetch book links from a given page."""
    page_url = f"{base_url}?page={page}"
    response = requests.get(page_url)
    soup = BeautifulSoup(response.text, "html.parser")
    
    book_links = []
    for link in soup.find_all('h4'):
        alink = link.find('a')
        if alink is not None:
            book_links.append(alink['href'])
    return book_links

def get_book_genre(book_url):
    """Fetch the genre of a given book."""
    full_url = f"{base_url}{book_url}"
    response = requests.get(full_url)
    soup = BeautifulSoup(response.text, "html.parser")

    book_title_div = soup.find('div', class_='row book-list-item pt-4')
    book_title = book_title_div.find('a', attrs = {"href":book_url}).text
    # print(book_title)
    genre_list = []
    genre_section = soup.find('div', class_='tab-pane fade d-sm-none')
    # print(genre_section)
    if genre_section:
        for genre in genre_section.find_all('a'):
            # print(genre.text)            
            genre_list.append(genre.text)
    return (book_title, genre_list)
#page_limit=1
def scrape_books(page_limit=1):
    """Scrape book links and genres, and return a DataFrame."""
    all_books = []

    for page in range(1, page_limit + 1):
        book_links = get_book_links(page)
        for book_link in book_links:
            book_title , genre_list = get_book_genre(book_link)
            all_books.append({"Title": book_title, "Genres": genre_list})

    return pd.DataFrame(all_books)

# Scrape books from the first page as an example
df_books = scrape_books(page_limit=375)
print(df_books)
